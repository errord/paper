# 第二章 理论基础与模型构建

## 2.1 理论基础

### 2.1.1 现代资产配置理论

**均值-方差模型。** Markowitz（1952）奠定了现代投资组合理论的基石，将资产配置问题形式化为在给定风险水平下最大化期望收益的优化问题：

$$
\max_{\mathbf{w}} \quad \mathbf{w}^\top \boldsymbol{\mu} - \frac{\lambda}{2} \mathbf{w}^\top \boldsymbol{\Sigma} \mathbf{w}
$$

$$
\text{s.t.} \quad \mathbf{w}^\top \mathbf{1} = 1, \quad \mathbf{w} \geq \mathbf{0}
$$

其中 $\mathbf{w} \in \mathbb{R}^n$ 为权重向量，$\boldsymbol{\mu} \in \mathbb{R}^n$ 为预期收益向量，$\boldsymbol{\Sigma} \in \mathbb{R}^{n \times n}$ 为协方差矩阵，$\lambda$ 为风险厌恶系数。该模型的理论优雅性与实践局限性并存：最优解对输入参数 $\boldsymbol{\mu}$ 和 $\boldsymbol{\Sigma}$ 高度敏感（Best & Grauer, 1991），且在高维情形下协方差矩阵的估计误差随维度平方级增长（Ledoit & Wolf, 2004）。

**Black-Litterman模型。** Black与Litterman（1992）通过贝叶斯框架将市场均衡收益与投资者主观观点融合，有效缓解了均值-方差模型的输入敏感性问题。模型将市场隐含均衡收益 $\boldsymbol{\pi} = \lambda \boldsymbol{\Sigma} \mathbf{w}_{mkt}$ 作为先验，投资者观点 $\mathbf{P}\boldsymbol{\mu} = \mathbf{q} + \boldsymbol{\varepsilon}$（$\boldsymbol{\varepsilon} \sim N(\mathbf{0}, \boldsymbol{\Omega})$）作为似然，得到后验期望收益：

$$
\hat{\boldsymbol{\mu}} = [(\tau\boldsymbol{\Sigma})^{-1} + \mathbf{P}^\top \boldsymbol{\Omega}^{-1} \mathbf{P}]^{-1} [(\tau\boldsymbol{\Sigma})^{-1}\boldsymbol{\pi} + \mathbf{P}^\top \boldsymbol{\Omega}^{-1}\mathbf{q}]
$$

该模型在实践中被广泛采用，但其核心仍依赖协方差矩阵的准确估计，且未考虑资产间依赖结构的非线性特征。

**风险平价模型。** 风险平价（Risk Parity）策略要求每项资产对组合总风险的边际贡献相等（Maillard, Roncalli & Teiletche, 2010）。定义资产 $i$ 的风险贡献为：

$$
RC_i = w_i \cdot \frac{\partial \sigma_p}{\partial w_i} = w_i \cdot \frac{(\boldsymbol{\Sigma}\mathbf{w})_i}{\sqrt{\mathbf{w}^\top\boldsymbol{\Sigma}\mathbf{w}}}
$$

风险平价条件要求 $RC_i = RC_j, \forall i,j$，等价于求解：

$$
\min_{\mathbf{w}} \sum_{i=1}^{n}\sum_{j=1}^{n}\left(w_i(\boldsymbol{\Sigma}\mathbf{w})_i - w_j(\boldsymbol{\Sigma}\mathbf{w})_j\right)^2
$$

$$
\text{s.t.} \quad \mathbf{w}^\top \mathbf{1} = 1, \quad \mathbf{w} \geq \mathbf{0}
$$

该方法不要求预期收益估计，仅依赖协方差矩阵，具有更高的稳健性。但其隐含假设所有资产具有相同的风险调整后收益（Sharpe比率），且在资产高度相关时无法有效分散系统性风险。

**层次化风险平价（HRP）。** López de Prado（2016）提出基于层次聚类的投资组合构建方法，利用树状结构替代逆协方差矩阵进行权重分配，有效回避了矩阵求逆的数值不稳定性。HRP通过三个步骤实现：（1）基于相关距离矩阵进行层次聚类；（2）根据聚类树重排协方差矩阵；（3）沿树结构递归进行反方差分配。HRP本质上引入了资产间的层次依赖结构，为本文将图拓扑信息纳入配置框架提供了方法论先导。

### 2.1.2 复杂网络理论在金融中的应用

**金融网络的理论根基。** 将金融市场建模为网络的研究始于Mantegna（1999），其核心洞见在于：资产收益率之间的相关性结构蕴含了超越两两关系的高阶依赖信息，而图模型恰好提供了表达和分析这种高阶结构的数学工具。

形式化地，定义金融资产网络为图 $G = (V, E, W)$，其中 $V = \{v_1, \ldots, v_n\}$ 为资产节点集，$E \subseteq V \times V$ 为边集，$W: E \to \mathbb{R}^+$ 为边权函数。边权通常由资产收益率相关系数经距离变换获得。

**网络中心性的经济学含义。** 网络中心性度量了节点在网络中的结构重要性，不同中心性指标反映了不同的经济学含义：

（1）**度中心性**（Degree Centrality）：$C_D(i) = \frac{k_i}{n-1}$，其中 $k_i$ 为节点 $i$ 的度数。度中心性衡量资产与其他资产的直接关联数目，高度中心性意味着该资产与众多资产存在强相关性，是市场共同因子的直接承载者。

（2）**介数中心性**（Betweenness Centrality）：

$$
C_B(i) = \sum_{s \neq i \neq t} \frac{\sigma_{st}(i)}{\sigma_{st}}
$$

其中 $\sigma_{st}$ 为节点 $s$ 到 $t$ 的最短路径数，$\sigma_{st}(i)$ 为经过节点 $i$ 的最短路径数。介数中心性衡量资产在风险传导路径中的"桥梁"作用，高介数中心性的资产是风险传染的关键中介节点（Billio et al., 2012）。

（3）**特征向量中心性**（Eigenvector Centrality）：$C_E(i) = \frac{1}{\lambda_1}\sum_{j \in \mathcal{N}(i)} C_E(j)$，其中 $\lambda_1$ 为邻接矩阵的最大特征值。特征向量中心性衡量节点是否与其他高中心性节点相连，高特征向量中心性的资产不仅自身处于网络核心，且其邻居也处于核心位置，反映了系统性风险的集聚效应。

（4）**接近中心性**（Closeness Centrality）：$C_C(i) = \frac{n-1}{\sum_{j \neq i} d(i,j)}$，其中 $d(i,j)$ 为节点间最短路径长度。接近中心性衡量资产到网络中所有其他资产的平均距离，高接近中心性的资产对市场整体波动的响应更为迅速。

**社区结构与资产聚类。** 网络中的社区结构（Community Structure）反映了资产的自然聚类特征。Girvan与Newman（2002）定义的模块度（Modularity）指标：

$$
Q = \frac{1}{2m}\sum_{ij}\left[A_{ij} - \frac{k_ik_j}{2m}\right]\delta(c_i, c_j)
$$

其中 $m$ 为总边数，$A_{ij}$ 为邻接矩阵元素，$c_i$ 为节点 $i$ 所属社区，$\delta(\cdot,\cdot)$ 为Kronecker函数。高模块度表明网络存在明显的群组结构，对应于资产市场中的板块效应或行业聚集现象。社区划分为跨群组分散化提供了自然的分组依据。

### 2.1.3 协方差矩阵的稳健估计

传统样本协方差矩阵在高维小样本情形下（$n/T$ 较大时）存在严重的估计偏差，其条件数过大导致矩阵求逆不稳定（Marchenko & Pastur, 1967）。本文采用两种互补的稳健估计方法：

**Ledoit-Wolf收缩估计。** Ledoit与Wolf（2004）提出将样本协方差矩阵向结构化目标收缩：

$$
\hat{\boldsymbol{\Sigma}}_{LW} = \alpha \mathbf{F} + (1-\alpha)\mathbf{S}
$$

其中 $\mathbf{S}$ 为样本协方差矩阵，$\mathbf{F}$ 为收缩目标（如恒定相关模型），$\alpha \in [0,1]$ 为最优收缩强度，由渐近最优公式解析确定。收缩估计在均方误差意义下优于样本协方差矩阵，且保证正定性。

**Graphical LASSO。** Friedman等（2008）提出通过 $\ell_1$ 正则化估计精度矩阵（协方差逆矩阵）：

$$
\hat{\boldsymbol{\Theta}} = \arg\max_{\boldsymbol{\Theta} \succ 0} \left[\log\det\boldsymbol{\Theta} - \text{tr}(\mathbf{S}\boldsymbol{\Theta}) - \rho\|\boldsymbol{\Theta}\|_1\right]
$$

其中 $\boldsymbol{\Theta} = \boldsymbol{\Sigma}^{-1}$ 为精度矩阵，$\rho > 0$ 为正则化参数。Graphical LASSO具有双重功能：一方面提供稳健的协方差逆矩阵估计；另一方面，精度矩阵的稀疏结构直接对应于资产间的**条件独立性**关系——$\Theta_{ij} = 0$ 意味着在控制其他所有资产后，资产 $i$ 与 $j$ 条件独立。这为构建基于条件依赖关系的资产网络提供了替代路径（详见2.3节）。

---

## 2.2 图模型与资产配置的理论衔接

本节论证图模型用于资产配置的理论合理性，建立从网络拓扑特征到投资组合权重的完整推理链条。

### 2.2.1 核心命题：网络中心性与系统性风险

**命题1（中心性-风险传染假说）。** 在金融资产网络中，中心性较高的资产具有更强的风险传染能力和系统性风险暴露。

**论证。** 该命题的理论基础来自三个层面：

**（1）风险传染的网络效应。** Billio等（2012）通过Granger因果网络分析证实，金融机构之间的系统性风险通过网络结构传播，处于网络核心位置（高中心性）的机构对系统性风险的贡献显著更大。Diebold与Yılmaz（2014）进一步构建了基于方差分解的溢出指数网络，证明网络中心性与风险溢出强度之间存在正相关关系。将此逻辑推广至资产层面：在相关性网络中，高中心性资产意味着与众多其他资产存在强相关关系，当市场遭受冲击时，这些资产既是风险的接收者也是传播者，其价格波动会通过网络结构迅速扩散。

**（2）共同因子暴露的结构化表达。** 从因子模型视角，资产收益率可分解为：

$$
r_i = \alpha_i + \sum_{k=1}^{K}\beta_{ik}f_k + \varepsilon_i
$$

资产间的相关性主要由共同因子载荷 $\boldsymbol{\beta}_i$ 驱动。在相关性网络中，高中心性资产对应于对共同因子具有高载荷的资产——它们与众多资产相关，恰恰因为它们共享了更多的系统性因子。因此，降低高中心性资产的配置权重，本质上是降低组合对系统性因子的集中暴露。

**（3）尾部风险的网络放大效应。** Acemoglu等（2015）从理论上证明，在高度连接的网络中，微观冲击可以通过网络结构放大为宏观波动。当网络呈现"星型"或"核心-外围"结构时（即存在少数高中心性节点），系统对这些核心节点的冲击尤为脆弱。降低核心节点权重可视为对此结构性脆弱性的防御。

**命题2（社区结构-分散化假说）。** 网络社区结构揭示了资产的内生聚类特征，跨社区分散化优于随机分散化。

**论证。** 网络中的社区对应于强相关的资产子集，社区内部资产的相关性显著高于社区之间。这与传统资产配置中的行业/风格分类具有相似功能，但社区检测是纯数据驱动的，能够捕捉传统分类体系遗漏的隐性关联模式。例如，在市场压力时期，原本不同行业的资产可能因共同的流动性因子而归入同一社区。跨社区配置资产，确保组合暴露于不同的相关性集群，提供了更本质的分散化。

### 2.2.2 现有网络配置规则的比较与选择

已有文献提出了多种基于网络中心性的配置规则，本节系统比较其理论依据与适用条件：

**规则1：反中心性加权。** $w_i \propto (1 - C(i))$，其中 $C(i)$ 为归一化中心性指标。该规则由Pozzi等（2013）提出，直觉为"远离网络核心即远离系统性风险"。优点在于简洁直观，缺点在于完全规避中心性高的资产可能牺牲预期收益，且当所有资产中心性接近时退化为等权。

**规则2：中心性直接加权。** $w_i \propto C(i)$。该规则假设高中心性资产具有更高的信息效率或流动性溢价，适用于动量策略或流动性偏好的投资者（Výrost et al., 2019）。但在风险管理导向的配置中，该规则与分散化目标相悖。

**规则3：PageRank加权。** $w_i \propto PR(i)$，其中 $PR(i)$ 为节点的PageRank值。PageRank综合考虑了直接连接数目和邻居的重要性，比简单度中心性更为精细，但其经济学含义不如介数中心性直接。

**规则4：网络正则化风险平价（本文方法）。** 本文提出将网络拓扑信息作为正则化项嵌入风险平价优化框架，而非作为独立的权重决定规则：

$$
\min_{\mathbf{w}} \sum_{i=1}^{n}\sum_{j=1}^{n}\left(RC_i - RC_j\right)^2 + \gamma \sum_{i=1}^{n} C_B(i) \cdot w_i^2
$$

$$
\text{s.t.} \quad \mathbf{w}^\top \mathbf{1} = 1, \quad \mathbf{w} \geq \mathbf{0}, \quad \text{业务约束}
$$

其中 $RC_i = w_i \cdot (\boldsymbol{\Sigma}\mathbf{w})_i / \sigma_p$ 为资产 $i$ 的风险贡献，$C_B(i)$ 为归一化介数中心性，$\gamma \geq 0$ 为网络正则化强度参数。

**选择介数中心性作为正则化变量的理由：**

- 介数中心性直接度量了节点在风险传导路径中的"桥梁"角色，与命题1的风险传染机制最为对应；
- 度中心性仅反映直接连接数，无法捕捉间接传导路径；特征向量中心性反映的是核心集聚效应，在MST等稀疏图上区分度较低；接近中心性在树结构上与介数中心性高度相关（Barthélemy, 2004），信息冗余；
- 实证文献表明，介数中心性在预测系统性风险传播方面优于其他中心性指标（Battiston et al., 2012）。

**网络正则化风险平价的理论优势：**

相较于简单的反中心性加权规则（规则1），本方法具有以下优势：

（a）**保留风险平价的均衡性质。** 当 $\gamma = 0$ 时退化为标准风险平价，确保模型在网络信息缺失时仍具有合理配置；当 $\gamma > 0$ 时，网络信息作为额外约束进入，而非替代风险均衡原则。

（b）**渐进式惩罚而非硬性排斥。** 高中心性资产不会被直接排除，而是在风险贡献均等的基础上受到额外的权重惩罚，惩罚力度与中心性成正比。这比二元式的"核心/外围"分类更为精细。

（c）**经济学含义明确。** 正则化项 $\gamma \sum_i C_B(i) \cdot w_i^2$ 可解读为对网络中介风险的惩罚：配置在高介数节点上的权重越大，组合暴露于网络传染路径的风险越高。$\gamma$ 控制了投资者对网络传染风险的厌恶程度。

（d）**兼容业务约束。** 优化框架天然支持券商自营投资的业务约束（如固收下限、权益上限、单一标的集中度限制），而简单加权规则难以纳入此类约束。

### 2.2.3 不同中心性指标的比较框架

为确保结论的稳健性，本文在实证部分将对比以下中心性指标作为正则化变量的效果：

| 中心性指标 | 经济学含义 | 理论适用场景 | 预期效果 |
|---|---|---|---|
| 介数中心性 $C_B$ | 风险传导桥梁 | 系统性风险防范 | 降低极端市场条件下的尾部风险 |
| 度中心性 $C_D$ | 直接关联广度 | 共同因子暴露控制 | 降低组合对市场因子的集中暴露 |
| 特征向量中心性 $C_E$ | 核心集聚程度 | 核心-外围结构市场 | 避免集中配置于核心资产群 |
| 接近中心性 $C_C$ | 市场冲击响应速度 | 流动性风险管理 | 降低组合对快速传播冲击的敏感性 |

通过将四种中心性指标分别代入正则化项，比较配置结果的差异，验证指标选择的稳健性。若不同指标产生显著不同的配置结果，这一差异本身即是有价值的信息，提示投资者关注特定网络特征。

---

## 2.3 图模型构建方法论

### 2.3.1 相关性度量与距离变换

设 $n$ 项资产在时间窗口 $[t-\tau, t]$ 内的对数收益率序列为 $\{r_{i,s}\}_{s=t-\tau}^{t}$，$i = 1, \ldots, n$。计算Pearson相关系数矩阵：

$$
\rho_{ij} = \frac{\text{Cov}(r_i, r_j)}{\sigma_i \sigma_j}
$$

将相关系数转化为满足度量空间公理的距离：

$$
d_{ij} = \sqrt{2(1 - \rho_{ij})}
$$

**度量性质验证。** 该距离函数满足（Mantegna, 1999）：（1）非负性：$d_{ij} \geq 0$；（2）同一性：$d_{ij} = 0 \Leftrightarrow \rho_{ij} = 1$；（3）对称性：$d_{ij} = d_{ji}$；（4）三角不等式：$d_{ij} \leq d_{ik} + d_{kj}$。满足欧几里得度量性质保证了后续MST和PMFG构建的数学合法性。

**替代距离函数。** 作为稳健性检验，本文同时考虑非线性距离变换 $d_{ij}' = \sqrt{1 - \rho_{ij}^2}$（基于互信息的近似），以评估线性相关假设对结果的影响。

### 2.3.2 网络过滤方法

由完全相关矩阵直接构建的网络包含 $n(n-1)/2$ 条边，噪音严重且难以分析。本文采用两种互补的网络过滤方法：

**方法一：最小生成树（MST）。** 对完全加权图 $G = (V, E, d)$，使用Kruskal算法（Kruskal, 1956）求最小生成树：

$$
T^* = \arg\min_{T \in \mathcal{T}} \sum_{(i,j) \in T} d_{ij}
$$

其中 $\mathcal{T}$ 为所有生成树的集合。MST保留 $n-1$ 条边，提取了资产间最强的层级依赖结构。

**MST的结构性质。** 对于 $n$ 个节点的MST：
- 恰好包含 $n-1$ 条边；
- 平均度为 $\bar{k} = 2(n-1)/n$；
- 不含环路，为树结构；
- 任意两节点间存在唯一路径。

**MST的局限性。** MST仅保留 $n-1$ 条边（信息压缩比约 $2/n$），可能因单条边的变化而导致社区结构的大幅重组。此外，MST上的模块度计算需谨慎解读——由于树结构无环路，传统模块度优化在MST上的意义有限，社区检测应在信息更丰富的网络（如PMFG或原始阈值网络）上进行。

**方法二：平面最大过滤图（PMFG）。** Tumminello等（2005）提出PMFG，保留 $3(n-2)$ 条边，同时要求所得图嵌入在平面（亏格为零的曲面）上：

$$
G^*_{PMFG} = \arg\max_{G \in \mathcal{P}} \sum_{(i,j) \in G} \rho_{ij}
$$

其中 $\mathcal{P}$ 为所有平面图的集合。PMFG相比MST保留了约3倍的边信息，能更准确地刻画社区结构和中心性分布，且MST是PMFG的子图。

**两种过滤方法的互补性：**

| 性质 | MST | PMFG |
|---|---|---|
| 边数 | $n-1$ | $3(n-2)$ |
| 信息保留 | 骨干层级结构 | 社区内部连接+跨社区桥梁 |
| 中心性计算 | 度中心性区分度有限 | 所有中心性指标均有效 |
| 社区检测 | 不适用（无环路） | 适用（含环路结构） |
| 计算复杂度 | $O(n^2\log n)$ | $O(n^2)$（贪心算法） |
| 适用场景 | 层级结构分析、快速预览 | 社区检测、中心性度量、权重优化 |

**本文策略。** 采用PMFG作为主要网络构建方法，用于社区检测和中心性计算，进而嵌入配置模型。MST作为辅助工具用于可视化和层级结构分析。对比两种过滤方法下的配置结果以评估稳健性。

### 2.3.3 基于Graphical LASSO的条件依赖网络

除基于相关性的过滤网络外，本文构建基于**条件独立性**的替代网络作为稳健性检验。利用Graphical LASSO（Friedman et al., 2008）估计稀疏精度矩阵 $\hat{\boldsymbol{\Theta}}$，定义条件依赖网络：

$$
A_{ij}^{GL} = \begin{cases} 1, & \text{if } \hat{\Theta}_{ij} \neq 0, \, i \neq j \\ 0, & \text{otherwise} \end{cases}
$$

该网络中的边表示控制其他所有资产后仍存在的直接依赖关系，排除了由共同因子导致的伪相关。当相关性网络与条件依赖网络给出一致的社区结构和中心性排序时，增强了结论的可信度。

### 2.3.4 网络显著性检验

MST和PMFG总是可以从任意相关矩阵中构建，即使数据来自独立同分布的随机变量。因此，必须检验观察到的网络拓扑特征是否显著偏离随机水平。

**检验方法一：随机矩阵理论（RMT）基准。** 根据Marchenko-Pastur定律（1967），若 $n$ 项资产的 $T$ 期收益率为独立同分布，则样本相关矩阵的特征值分布趋近于：

$$
f(\lambda) = \frac{T}{2\pi\sigma^2}\frac{\sqrt{(\lambda_+ - \lambda)(\lambda - \lambda_-)}}{\lambda}
$$

其中 $\lambda_{\pm} = \sigma^2(1 \pm \sqrt{n/T})^2$。落在 $[\lambda_-, \lambda_+]$ 之外的特征值携带真实的相关性信号。本文首先通过RMT确认相关矩阵中存在超越噪音的有效信号。

**检验方法二：随机网络对比。** 生成1000组与观测数据维度相同的随机收益率矩阵（保持各资产的边际分布但破坏相关结构），分别构建MST和PMFG，统计随机网络的拓扑指标（平均路径长度、聚集系数、模块度等）分布。若观测网络的指标显著偏离随机分布（$p < 0.05$），则确认网络拓扑特征反映了真实的市场结构而非统计噪音。

**检验方法三：度分布保持的重连检验。** 在保持原始网络度分布不变的前提下，随机重连边（Maslov & Sneppen, 2002），检验社区结构和核心节点是否仅由度分布决定，还是反映了更深层的连接模式。

---

## 2.4 基于网络拓扑的资产配置模型

### 2.4.1 社区检测与资产分组

在PMFG网络上应用Louvain算法（Blondel et al., 2008）进行社区检测，该算法通过两阶段迭代优化模块度：

$$
\Delta Q = \frac{1}{2m}\left[\frac{\sum_{in} + 2k_{i,in}}{2m} - \left(\frac{\sum_{tot} + k_i}{2m}\right)^2\right] - \frac{1}{2m}\left[\frac{\sum_{in}}{2m} - \left(\frac{\sum_{tot}}{2m}\right)^2 - \left(\frac{k_i}{2m}\right)^2\right]
$$

其中 $\sum_{in}$ 为社区内部边权之和，$\sum_{tot}$ 为社区内节点度之和，$k_i$ 为节点 $i$ 的度，$k_{i,in}$ 为节点 $i$ 与社区内部的连接权重。

社区划分结果将 $n$ 项资产分为 $K$ 个社区 $\{S_1, S_2, \ldots, S_K\}$，满足 $\bigcup_{k=1}^{K} S_k = V$ 且 $S_k \cap S_l = \emptyset, \forall k \neq l$。

**为何在PMFG而非MST上进行社区检测。** MST为树结构（无环路），模块度的极大化在树上的行为与含环网络本质不同——树的任意划分都不存在社区"内部的额外连接"（因为切断任意一条边都将树分为两个连通分量），导致社区检测在MST上缺乏统计效力。PMFG包含 $3(n-2)$ 条边和丰富的环路结构，为模块度优化提供了充分的统计信息。

### 2.4.2 两层配置框架

本文采用两层配置框架，将社区结构与网络正则化风险平价相结合：

**第一层：跨社区配置。** 将每个社区视为一个"超级资产"，社区收益率定义为社区内资产的等权平均：

$$
r_{S_k} = \frac{1}{|S_k|}\sum_{i \in S_k} r_i
$$

在社区层面应用风险平价，确定各社区的配置比例 $\{W_{S_1}, \ldots, W_{S_K}\}$：

$$
\min_{\{W_{S_k}\}} \sum_{k=1}^{K}\sum_{l=1}^{K}\left(RC_{S_k} - RC_{S_l}\right)^2
$$

$$
\text{s.t.} \quad \sum_{k=1}^{K}W_{S_k} = 1, \quad W_{S_k} \geq 0
$$

跨社区风险平价确保组合在不同相关性集群之间均衡分散，实现了命题2的跨社区分散化目标。

**第二层：社区内部配置。** 在每个社区 $S_k$ 内部，应用网络正则化风险平价（第2.2.2节规则4），确定社区内各资产的相对权重 $\{w_i^{(k)}\}_{i \in S_k}$：

$$
\min_{\{w_i^{(k)}\}} \sum_{i,j \in S_k}\left(RC_i^{(k)} - RC_j^{(k)}\right)^2 + \gamma \sum_{i \in S_k} C_B(i) \cdot \left(w_i^{(k)}\right)^2
$$

$$
\text{s.t.} \quad \sum_{i \in S_k} w_i^{(k)} = 1, \quad w_i^{(k)} \geq 0
$$

其中 $RC_i^{(k)} = w_i^{(k)} \cdot (\boldsymbol{\Sigma}_{S_k}\mathbf{w}^{(k)})_i / \sigma_{S_k}$，$\boldsymbol{\Sigma}_{S_k}$ 为社区 $S_k$ 内资产的协方差矩阵。

**最终权重合成。** 资产 $i$（属于社区 $S_k$）的最终配置权重为：

$$
w_i^{final} = W_{S_k} \cdot w_i^{(k)}
$$

### 2.4.3 业务约束的整合

证券公司自营投资面临监管与内部风控的多重约束。本文将以下业务约束纳入优化框架：

（1）**资产类别约束：** 固定收益类配置不低于总头寸的 $\alpha_{min}$（如60%），权益类配置不超过 $\alpha_{max}$（如30%）：

$$
\sum_{i \in \mathcal{FI}} w_i^{final} \geq \alpha_{min}, \quad \sum_{i \in \mathcal{EQ}} w_i^{final} \leq \alpha_{max}
$$

（2）**单一标的集中度约束：** 任意单一资产权重不超过 $\beta_{max}$（如10%）：

$$
w_i^{final} \leq \beta_{max}, \quad \forall i
$$

（3）**换手率约束：** 相邻调仓期权重变动的 $L_1$ 范数不超过上限 $\delta_{max}$：

$$
\sum_{i=1}^{n} |w_{i,t}^{final} - w_{i,t-1}^{final}| \leq \delta_{max}
$$

上述约束以线性或二次约束形式嵌入两层优化框架中。当约束与网络正则化风险平价的解产生冲突时，优先满足业务约束，网络正则化在可行域内寻找最优解。

### 2.4.4 正则化参数 $\gamma$ 的选择

参数 $\gamma$ 控制网络拓扑信息对配置结果的影响强度，其选择通过以下方法确定：

**交叉验证法。** 将样本期按时间序列分为训练集（前70%）和验证集（后30%），在训练集上对 $\gamma \in \{0, 0.1, 0.5, 1.0, 2.0, 5.0\}$ 网格搜索，选择在验证集上最大化夏普比率（或最小化CVaR）的 $\gamma^*$。

**经济学解释。** $\gamma = 0$ 表示完全忽略网络信息，退化为标准风险平价；$\gamma \to \infty$ 表示完全由中心性决定权重（高中心性资产权重趋于零）。合理的 $\gamma^*$ 应在两者之间，反映网络信息的边际价值。

---

## 2.5 网络时变性与动态配置框架

### 2.5.1 资产相关性的时变特征

金融资产的相关性结构并非静态不变。大量实证研究表明，资产相关性在市场压力时期显著上升（"相关性崩溃"现象，Longin & Solnik, 2001），在不同货币政策周期和经济状态中呈现结构性变化（Engle, 2002）。使用固定时间窗口构建单一静态网络，隐含了"相关结构稳定"的强假设，可能导致：

- 在市场剧变时期，网络拓扑已发生本质变化，但配置策略仍基于过时的网络结构；
- 社区成员的动态调整被忽视，某些资产可能在不同时期属于不同社区；
- 中心性排序的变化未被捕捉，原先的外围资产可能因结构性变化成为新的风险传导核心。

### 2.5.2 滚动窗口网络构建

为捕捉网络的时变特征，本文采用滚动窗口方法动态更新网络结构。设滚动窗口长度为 $\tau$（本文取 $\tau = 252$ 个交易日，约一年），步长为 $\Delta$（本文取 $\Delta = 21$ 个交易日，约一个月），则在时点 $t$ 的网络 $G_t$ 基于 $[t-\tau, t]$ 的数据构建。

**窗口长度的选择依据。** 窗口过短（如 $\tau = 63$，一个季度）导致相关矩阵估计噪音过大，网络结构剧烈波动；窗口过长（如 $\tau = 504$，两年）导致网络过度平滑，无法捕捉结构性变化。$\tau = 252$ 在估计精度与时变性之间取得平衡，且与年度风险预算周期吻合。

### 2.5.3 网络稳定性度量

为监测网络结构的变化并决定是否需要调仓，定义以下网络稳定性指标：

**边重叠率：**

$$
J(G_t, G_{t-\Delta}) = \frac{|E_t \cap E_{t-\Delta}|}{|E_t \cup E_{t-\Delta}|}
$$

即相邻时间窗口网络的Jaccard相似系数。$J$ 越高表示网络越稳定。

**中心性秩相关：**

$$
\rho_s(t) = \text{Spearman}\left(\{C_B^{(t)}(i)\}_{i=1}^n, \{C_B^{(t-\Delta)}(i)\}_{i=1}^n\right)
$$

即相邻时间窗口中心性排序的Spearman秩相关系数。若 $\rho_s(t)$ 显著下降，表明风险传导结构发生质变。

**社区稳定性：** 使用归一化互信息（NMI）度量相邻时间窗口社区划分的一致性：

$$
NMI(t) = \frac{2I(\mathcal{C}_t; \mathcal{C}_{t-\Delta})}{H(\mathcal{C}_t) + H(\mathcal{C}_{t-\Delta})}
$$

其中 $I(\cdot;\cdot)$ 为互信息，$H(\cdot)$ 为熵。

**自适应调仓规则。** 当网络稳定性指标低于预设阈值（如 $J < 0.7$ 或 $NMI < 0.8$）时，触发网络重构和权重调整；否则维持原有配置，降低不必要的换手成本。

---

## 2.6 统计检验与稳健性论证框架

### 2.6.1 策略绩效的统计显著性

投资策略的样本外绩效可能仅是随机波动的结果。为确保结论的科学性，本文对所有策略比较进行严格的统计检验：

**检验一：Ledoit-Wolf夏普比率检验。** Ledoit与Wolf（2008）提出了基于HAC（异方差自相关一致）估计量的夏普比率差异检验，适用于非正态、序列相关的收益率数据。原假设 $H_0: SR_A = SR_B$，备择假设 $H_1: SR_A > SR_B$。

**检验二：Bootstrap检验。** 采用分块Bootstrap（Block Bootstrap, Politis & Romano, 1994）保持收益率序列的时间依赖结构，生成10000组模拟样本，构建绩效指标的置信区间和经验 $p$ 值。

**检验三：Diebold-Mariano检验。** Diebold与Mariano（1995）检验用于比较两个策略的预测能力差异，原假设为两策略的损失函数期望相等。本文以组合方差（或CVaR）为损失函数，检验网络增强策略是否显著优于基准策略。

### 2.6.2 多重比较修正

当同时比较多个策略对时，存在多重比较问题（Family-Wise Error Rate膨胀）。本文采用Romano-Wolf逐步下降方法（Romano & Wolf, 2005）控制族错误率，确保各对比较的显著性结论在联合检验意义下仍然有效。

### 2.6.3 模型稳健性检验

**（1）网络过滤方法稳健性。** 比较MST、PMFG和Graphical LASSO三种网络构建方法下的配置结果，若主要结论在不同网络下一致，则稳健性得到确认。

**（2）窗口长度敏感性。** 对 $\tau \in \{126, 189, 252, 378, 504\}$（半年至两年）进行敏感性分析，检验结论对窗口选择的依赖程度。

**（3）样本期稳健性。** 划分不同市场状态（牛市、熊市、震荡市），分别评估策略绩效，确认策略不仅在特定市场条件下有效。

**（4）参数稳健性。** 对正则化参数 $\gamma$ 进行网格搜索的同时，报告绩效指标随 $\gamma$ 变化的曲线，确认最优 $\gamma^*$ 附近的结果平坦而非尖锐（排除过拟合）。

**（5）交易成本敏感性。** 在不同交易成本假设（单边0bp、5bp、10bp、20bp）下重新评估策略净收益，确认扣除交易成本后策略仍具有经济显著性。

---

*本章建立了从理论假说到模型构建、从静态分析到动态框架、从点估计到统计推断的完整理论体系。核心创新在于将网络拓扑信息以正则化形式嵌入风险平价框架（网络正则化风险平价），而非简单地用中心性替代权重，从而在保留风险均衡优良性质的同时，有效利用图模型揭示的系统性风险传导结构。*
